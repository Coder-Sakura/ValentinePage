<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>python爬虫-pixiv关注画师作品[2]</title>
      <link href="/blog/2019/03/30/pixiv-two/"/>
      <url>/blog/2019/03/30/pixiv-two/</url>
      
        <content type="html"><![CDATA[<img src="/blog/2019/03/30/pixiv-two/HeadPicture.jpg"><hr><blockquote><h2 id="说在前面的话"><a href="#说在前面的话" class="headerlink" title="说在前面的话"></a>说在前面的话</h2><p>本篇概述：<a href="https://coder-sakura.github.io/blog/2019/03/27/pixiv-one/">上篇</a>的后续；主要是分析数据接口，拿到关注画师的所有作品的详细信息</p></blockquote><a id="more"></a><hr><h2 id="1、分析——关注界面"><a href="#1、分析——关注界面" class="headerlink" title="1、分析——关注界面"></a>1、分析——关注界面</h2><blockquote><p>关注界面(默认公开) <a href="https://www.pixiv.net/bookmark.php?type=user&amp;rest=show" target="_blank" rel="noopener">https://www.pixiv.net/bookmark.php?type=user&amp;rest=show</a> </p></blockquote><img src="/blog/2019/03/30/pixiv-two/1.png"><blockquote><p>这里关注画师全在公开界面，虽然非公开获取也是ok的</p><p>公开和非公开只是，<a href="https://www.pixiv.net/bookmark.php?type=user&amp;rest=show" target="_blank" rel="noopener">https://www.pixiv.net/bookmark.php?type=user&amp;rest=show</a> 后面分别是rest=show 和 rest=hide</p></blockquote><hr><blockquote><p>F12 查看 Elements ，寻找画师列表和页数</p><ol><li>画师列表全在一个 class=members 的 div 中</li><li>画师信息在user-data中，有作者 id、主页 url、作者 name</li></ol></blockquote><img src="/blog/2019/03/30/pixiv-two/2.png"><img src="/blog/2019/03/30/pixiv-two/4.png"><blockquote><ol start="3"><li>最大页数在一个 class=_pager-complex 的 div，倒数第二个li</li></ol></blockquote><img src="/blog/2019/03/30/pixiv-two/3.png"><hr><h2 id="2、代码——bs4匹配"><a href="#2、代码——bs4匹配" class="headerlink" title="2、代码——bs4匹配"></a>2、代码——bs4匹配</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 找到最大页数</span></span><br><span class="line">max_num = attention_html_soup.find(<span class="string">'div'</span>, attrs=&#123;<span class="string">'class'</span>, <span class="string">'_pager-complex'</span>&#125;).find_all(<span class="string">'li'</span>)[<span class="number">-2</span>].text</span><br><span class="line"><span class="comment"># 画师个人信息</span></span><br><span class="line">painter_information = attention_html_soup.find(<span class="string">'div'</span>, attrs=&#123;<span class="string">'class'</span>, <span class="string">'members'</span>&#125;).find_all(<span class="string">'div'</span>, attrs=&#123;<span class="string">'class'</span>, <span class="string">'userdata'</span>&#125;)</span><br></pre></td></tr></table></figure><h2 id="3、代码——获取关注画师的信息"><a href="#3、代码——获取关注画师的信息" class="headerlink" title="3、代码——获取关注画师的信息"></a>3、代码——获取关注画师的信息</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#获取关注画师界面的信息</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">attention_html</span><span class="params">(self)</span>:</span></span><br><span class="line">    <span class="comment"># self.return_to = 'https://www.pixiv.net/bookmark.php?type=user&amp;rest=show&amp;p='</span></span><br><span class="line">    <span class="comment"># p 是页数</span></span><br><span class="line">    attention_html = self.request(self.return_to)</span><br><span class="line">    attention_html_soup = BeautifulSoup(attention_html.text, <span class="string">'lxml'</span>)</span><br><span class="line">    <span class="comment">#获取最大页数</span></span><br><span class="line">    max_num = attention_html_soup.find(<span class="string">'div'</span>, attrs=&#123;<span class="string">'class'</span>, <span class="string">'_pager-complex'</span>&#125;).find_all(<span class="string">'li'</span>)[<span class="number">-2</span>].text</span><br><span class="line">    print(<span class="string">'最大页数为%s'</span> % (max_num))</span><br><span class="line">    <span class="keyword">for</span> num <span class="keyword">in</span> range(<span class="number">1</span>,int(max_num)+<span class="number">1</span>):</span><br><span class="line">        attention_html_url = self.return_to + str(num)      <span class="comment"># 构造每个页面的 url</span></span><br><span class="line">        attention_html = self.request(attention_html_url)</span><br><span class="line">        attention_html_soup = BeautifulSoup(attention_html.text,<span class="string">'lxml'</span>)</span><br><span class="line">        painter_information = attention_html_soup.find(<span class="string">'div'</span>, attrs=&#123;<span class="string">'class'</span>, <span class="string">'members'</span>&#125;).find_all(<span class="string">'div'</span>, attrs=&#123;<span class="string">'class'</span>, <span class="string">'userdata'</span>&#125;)  <span class="comment">#画师个人信息</span></span><br><span class="line">        <span class="keyword">for</span> painter <span class="keyword">in</span> painter_information:</span><br><span class="line">            <span class="comment"># userdata下的a标签中的data-user_id = 作者id</span></span><br><span class="line">            painter_id = painter.a[<span class="string">'data-user_id'</span>]</span><br><span class="line">            <span class="comment"># userdata下的a标签中的data-user_name = 作者name</span></span><br><span class="line">            name = painter.a[<span class="string">'data-user_name'</span>]</span><br><span class="line">            print(<span class="string">'&#123;0&#125;:&#123;1&#125;'</span>.format(name,painter_id))</span><br><span class="line">    print(<span class="string">'已获取所有关注画师的作品信息！！！！'</span>)</span><br></pre></td></tr></table></figure><blockquote><p>对于文笔不好的人来说，还是上代码来的舒服</p><p>毕竟 talk is cheap, show me code !</p></blockquote><hr><h2 id="4、分析——画师个人主页及数据流向"><a href="#4、分析——画师个人主页及数据流向" class="headerlink" title="4、分析——画师个人主页及数据流向"></a>4、分析——画师个人主页及数据流向</h2><blockquote><ol><li><p>这里说下，为什么不获取 user-data 里面的 href 属性？</p></li><li><p>正常流程不应该是拿到 href 然后访问 url,获取源码，拿到作品信息。</p></li><li><p>因为可以直接通过接口拿到这个画师的所有作品的数据。</p></li></ol></blockquote><hr><img src="/blog/2019/03/30/pixiv-two/5.png"><blockquote><p>该画师有73个作品，但是点击进入主页发现只有小小的一部分</p><p>勾上 Preserve log，点击查看全部</p></blockquote><img src="/blog/2019/03/30/pixiv-two/6.png"><blockquote><p>新加载的页面显示了所有的作品（虽然分为2页）</p><p>与之前的 XHR 比较，接下来的目标在红框标出来的三个文件（不一定全是我们的目标）</p></blockquote><hr><blockquote><p>点击第一个illust，发现 Preview 里是标签 tags （json数据）</p></blockquote><img src="/blog/2019/03/30/pixiv-two/7.png"><blockquote><p>点击第二个illust，Preview  里是作品信息 （json数据）</p></blockquote><img src="/blog/2019/03/30/pixiv-two/8.png"><blockquote><p>确定了第二个 illust 是目标之后，模仿它进行请求</p><p>但是发现他的 url 是一串巨长的字符串，由 一页的所有作品 id 和 is_manga_top=0 拼接而成</p><p>url 中作品 id 的拼接顺序是由新到旧（也就是数字大的在前面）</p></blockquote><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">url</span> = https://www.pixiv.net/ajax/user/1117751/profile/illusts?ids<span class="number">%5</span>B<span class="number">%5</span>D=73742388&amp;ids<span class="number">%5</span>B<span class="number">%5</span>D=71855085&amp;ids<span class="number">%5</span>B<span class="number">%5</span>D=71849582&amp;ids<span class="number">%5</span>B<span class="number">%5</span>D=71685985&amp;ids<span class="number">%5</span>B<span class="number">%5</span>D=68213121&amp;ids<span class="number">%5</span>B<span class="number">%5</span>D=67765964&amp;ids<span class="number">%5</span>B<span class="number">%5</span>D=67758280&amp;ids<span class="number">%5</span>B<span class="number">%5</span>D=67757922&amp;ids<span class="number">%5</span>B<span class="number">%5</span>D=67619936&amp;ids<span class="number">%5</span>B<span class="number">%5</span>D=67404010&amp;ids<span class="number">%5</span>B<span class="number">%5</span>D=66856979&amp;ids<span class="number">%5</span>B<span class="number">%5</span>D=65998170&amp;ids<span class="number">%5</span>B<span class="number">%5</span>D=65834643&amp;ids<span class="number">%5</span>B<span class="number">%5</span>D=65393332&amp;ids<span class="number">%5</span>B<span class="number">%5</span>D=63861794&amp;ids<span class="number">%5</span>B<span class="number">%5</span>D=63761535&amp;ids<span class="number">%5</span>B<span class="number">%5</span>D=63617575&amp;ids<span class="number">%5</span>B<span class="number">%5</span>D=63475838&amp;ids<span class="number">%5</span>B<span class="number">%5</span>D=63090307&amp;ids<span class="number">%5</span>B<span class="number">%5</span>D=62347061&amp;ids<span class="number">%5</span>B<span class="number">%5</span>D=62200016&amp;ids<span class="number">%5</span>B<span class="number">%5</span>D=62178209&amp;ids<span class="number">%5</span>B<span class="number">%5</span>D=61785521&amp;ids<span class="number">%5</span>B<span class="number">%5</span>D=61656195&amp;ids<span class="number">%5</span>B<span class="number">%5</span>D=61489588&amp;ids<span class="number">%5</span>B<span class="number">%5</span>D=60732958&amp;ids<span class="number">%5</span>B<span class="number">%5</span>D=60588424&amp;ids<span class="number">%5</span>B<span class="number">%5</span>D=60384884&amp;ids<span class="number">%5</span>B<span class="number">%5</span>D=59959669&amp;ids<span class="number">%5</span>B<span class="number">%5</span>D=59706889&amp;ids<span class="number">%5</span>B<span class="number">%5</span>D=59656129&amp;ids<span class="number">%5</span>B<span class="number">%5</span>D=59541311&amp;ids<span class="number">%5</span>B<span class="number">%5</span>D=59180046&amp;ids<span class="number">%5</span>B<span class="number">%5</span>D=58977788&amp;ids<span class="number">%5</span>B<span class="number">%5</span>D=58919004&amp;ids<span class="number">%5</span>B<span class="number">%5</span>D=58029173&amp;ids<span class="number">%5</span>B<span class="number">%5</span>D=57027442&amp;ids<span class="number">%5</span>B<span class="number">%5</span>D=57027347&amp;ids<span class="number">%5</span>B<span class="number">%5</span>D=56527887&amp;ids<span class="number">%5</span>B<span class="number">%5</span>D=56525716&amp;ids<span class="number">%5</span>B<span class="number">%5</span>D=56309403&amp;ids<span class="number">%5</span>B<span class="number">%5</span>D=56110382&amp;ids<span class="number">%5</span>B<span class="number">%5</span>D=55934890&amp;ids<span class="number">%5</span>B<span class="number">%5</span>D=55680445&amp;ids<span class="number">%5</span>B<span class="number">%5</span>D=54917440&amp;ids<span class="number">%5</span>B<span class="number">%5</span>D=54900477&amp;ids<span class="number">%5</span>B<span class="number">%5</span>D=54900429&amp;ids<span class="number">%5</span>B<span class="number">%5</span>D=54900380&amp;is_manga_top=0</span><br></pre></td></tr></table></figure><blockquote><p>下一步目标：既然有所有作品 id 拼接成的 id ，说明是有接口获取所有作品 id 的。</p></blockquote><hr><h2 id="5、模仿请求"><a href="#5、模仿请求" class="headerlink" title="5、模仿请求"></a>5、模仿请求</h2><blockquote><p>在 XHR 中继续寻找，发现一个叫 all 文件，点开 Preview （json数据）</p><p>all 的 Request URL: <a href="https://www.pixiv.net/ajax/user/1117751/profile/all" target="_blank" rel="noopener">https://www.pixiv.net/ajax/user/1117751/profile/all</a> ，/user/后面的数字是作者的 id</p><p>在 Preview 中发现 illusts (插画)属性 ，下面的应该就是作品 id 了，可以自己复制一个去验证一下。</p><p>补充：有些画师在 manga (漫画)属性也是有值的，所以这里需要和前面的 illusts 属性合并</p></blockquote><img src="/blog/2019/03/30/pixiv-two/9.png"><blockquote><p>Request URL 放到浏览器中去访问，将访问结果复制到 json.cn 进行格式化</p></blockquote><img src="/blog/2019/03/30/pixiv-two/10.png"><h2 id="6、代码——获取关注画师的所有作品信息"><a href="#6、代码——获取关注画师的所有作品信息" class="headerlink" title="6、代码——获取关注画师的所有作品信息"></a>6、代码——获取关注画师的所有作品信息</h2><blockquote><ol><li>获得关注画师的信息，比如 id、name</li><li>通过 <a href="https://www.pixiv.net/ajax/user/[画师id]/profile/all" target="_blank" rel="noopener">https://www.pixiv.net/ajax/user/[画师id]/profile/all</a> 来获取画师的所有作品 id</li><li>（单图 动图 多图 都在 illusts 属性中，漫画虽然是单图和多图，但在 manga属性 中）</li><li>接着通过构造作品 id 和 is_manga_top=0 的 url 去请求作品的详细信息</li></ol></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 获取关注画师界面的信息</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">attention_html</span><span class="params">(self)</span>:</span></span><br><span class="line">    <span class="comment"># self.return_to = 'https://www.pixiv.net/bookmark.php?type=user&amp;rest=show&amp;p='</span></span><br><span class="line">    <span class="comment"># p 是页数</span></span><br><span class="line">    attention_html = self.request(self.return_to)</span><br><span class="line">    attention_html_soup = BeautifulSoup(attention_html.text, <span class="string">'lxml'</span>)</span><br><span class="line">    <span class="comment"># 获取最大页数</span></span><br><span class="line">    max_num = attention_html_soup.find(<span class="string">'div'</span>, attrs=&#123;<span class="string">'class'</span>, <span class="string">'_pager-complex'</span>&#125;).find_all(<span class="string">'li'</span>)[<span class="number">-2</span>].text</span><br><span class="line">    print(<span class="string">'最大页数为%s'</span> % (max_num))</span><br><span class="line">    <span class="keyword">for</span> num <span class="keyword">in</span> range(<span class="number">1</span>,int(max_num)+<span class="number">1</span>):</span><br><span class="line">        attention_html_url = self.return_to + str(num)      <span class="comment"># 构造每个页面的 url</span></span><br><span class="line">        attention_html = self.request(attention_html_url)</span><br><span class="line">        attention_html_soup = BeautifulSoup(attention_html.text,<span class="string">'lxml'</span>)</span><br><span class="line">        painter_information = attention_html_soup.find(<span class="string">'div'</span>, attrs=&#123;<span class="string">'class'</span>, <span class="string">'members'</span>&#125;).find_all(<span class="string">'div'</span>, attrs=&#123;<span class="string">'class'</span>, <span class="string">'userdata'</span>&#125;)  <span class="comment">#画师个人信息</span></span><br><span class="line">        <span class="keyword">for</span> painter <span class="keyword">in</span> painter_information:</span><br><span class="line">            <span class="comment"># userdata下的a标签中的data-user_id = 作者id</span></span><br><span class="line">            painter_id = painter.a[<span class="string">'data-user_id'</span>]</span><br><span class="line">            <span class="comment"># userdata下的a标签中的data-user_name = 作者name</span></span><br><span class="line">            name = painter.a[<span class="string">'data-user_name'</span>]</span><br><span class="line">            print(<span class="string">'&#123;0&#125;:&#123;1&#125;'</span>.format(name,painter_id))</span><br><span class="line">            <span class="comment"># 构造url来获取作者的所有作品 id</span></span><br><span class="line">            ajax_url = <span class="string">'https://www.pixiv.net/ajax/user/&#123;0&#125;/profile/all'</span>.format(painter_id)</span><br><span class="line">            self.painter_picture(painter_id,ajax_url,name)</span><br><span class="line">    print(<span class="string">'获取所有关注画师信息完成！！！！'</span>) </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">painter_picture</span><span class="params">(self,painter_id,ajax_url,name)</span>:</span></span><br><span class="line">    ajax_html = self.request(ajax_url)</span><br><span class="line">    <span class="comment"># 使用json.loads()方法加载进来</span></span><br><span class="line">    ajax_json = json.loads(ajax_html.text)</span><br><span class="line">    ajax_illusts = ajax_json[<span class="string">"body"</span>][<span class="string">"illusts"</span>] </span><br><span class="line">ajax_manga = ajax_json[<span class="string">"body"</span>][<span class="string">"manga"</span>]</span><br><span class="line">    <span class="comment"># 判断是否有 manga 类型的作品</span></span><br><span class="line">    <span class="keyword">if</span> len(ajax_manga) == <span class="number">0</span>:</span><br><span class="line">        total_data_dict = dict(ajax_illusts)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># 合并 manga 和 illusts,并转换为字典</span></span><br><span class="line">        total_data_dict = dict(ajax_illusts, **ajax_manga)</span><br><span class="line">    <span class="comment"># 字典格式：id:None,所以取字典的keys，并转化为list</span></span><br><span class="line">    total_data = list(total_data_dict.keys())</span><br><span class="line">    <span class="comment"># 这里用的是冒泡排序（从小到大），刚好学到就用了</span></span><br><span class="line">    <span class="comment"># 其实更简单的是 list(set(total_data))[::-1]</span></span><br><span class="line">    <span class="comment"># 上面的代码得到的也是从大到小排序的作品id</span></span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> range(len_total<span class="number">-1</span>):</span><br><span class="line">        <span class="keyword">for</span> y <span class="keyword">in</span> range(len_total<span class="number">-1</span>-x):</span><br><span class="line">            <span class="keyword">if</span> total_data[y] &gt; total_data[y+<span class="number">1</span>]:</span><br><span class="line">                total_data[y],total_data[y+<span class="number">1</span>] = total_data[y+<span class="number">1</span>],total_data[y]</span><br><span class="line">    <span class="comment"># 从大到小排序的作品id</span></span><br><span class="line">    total_data = total_data[::<span class="number">-1</span>]</span><br><span class="line">    <span class="comment"># 按每48个分组,画师每页显示48个作品</span></span><br><span class="line">    limit_num = <span class="number">48</span></span><br><span class="line">    <span class="comment"># after_grouping_list = [[xxx,xxx,xxx],[48个id],[...]...]</span></span><br><span class="line">    after_grouping_list = [total_data[i:i+limit_num] <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,len(total_data),limit_num)]</span><br><span class="line">    print(<span class="string">'画师'</span>,name,<span class="string">'作品有：'</span>,len(after_grouping_list),<span class="string">'页'</span>)</span><br><span class="line">    <span class="comment"># 开始根据作品id来拼接url（就是那个一大串的url）</span></span><br><span class="line">    count = <span class="number">0</span>   <span class="comment"># 每拼接完48个+1</span></span><br><span class="line">    <span class="keyword">for</span> grouping_list <span class="keyword">in</span> after_grouping_list:</span><br><span class="line">        ids_big = <span class="string">'https://www.pixiv.net/ajax/user/&#123;&#125;/profile/illusts?'</span>.format(painter_id)</span><br><span class="line">        <span class="keyword">for</span> work_id <span class="keyword">in</span> grouping_list:</span><br><span class="line">            ids = <span class="string">'ids%5B%5D='</span> + work_id + <span class="string">'&amp;'</span></span><br><span class="line">            ids_big = ids_big + ids </span><br><span class="line">        works_url = ids_big + <span class="string">'is_manga_top=0'</span></span><br><span class="line">        count += <span class="number">1</span></span><br><span class="line">        print(<span class="string">'第%s页的works_url:%s'</span> % (count,works_url))</span><br><span class="line">        <span class="comment"># 发起请求获得第count页作品的详细信息</span></span><br><span class="line">        works_html = self.request(works_url)</span><br><span class="line">        works_json = json.loads(works_html.text)</span><br><span class="line">        works_data = works_json[<span class="string">"body"</span>][<span class="string">"works"</span>].values()</span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> works_data:</span><br><span class="line">            title = x[<span class="string">'title'</span>]</span><br><span class="line">            folder_id = x[<span class="string">'id'</span>]</span><br><span class="line">            tags = x[<span class="string">'tags'</span>]</span><br><span class="line">            small_url = x[<span class="string">'url'</span>]</span><br><span class="line">            pageCount = x[<span class="string">'pageCount'</span>]</span><br><span class="line">            print(<span class="string">'\n作品id:&#123;0&#125;\t作品页数:&#123;1&#125;'</span>.format(folder_id,pageCount))</span><br><span class="line">            print(<span class="string">'作品标题:&#123;0&#125;'</span>.format(title))</span><br><span class="line">            print(<span class="string">'作品标签:&#123;0&#125;'</span>.format(tags))</span><br><span class="line">            print(<span class="string">'作品250*250图片地址:&#123;0&#125;'</span>.format(small_url))</span><br></pre></td></tr></table></figure><blockquote><p>works_data = works_json[“body”][“works”].values() </p><p>因为 keys() 是作品 id，values() 里面也有，所以直接 values() 就好了</p></blockquote><img src="/blog/2019/03/30/pixiv-two/11.png"><h2 id="7、最后"><a href="#7、最后" class="headerlink" title="7、最后"></a>7、最后</h2><blockquote><p>本篇主要是分析数据接口，拿到关注画师的所有作品的详细信息</p><p>那么下篇再根据单图动图多图进行图片下载，预计文件存储、其他的小功能和最后的代码汇总得放在下下篇了。</p><p>へ(￣ ￣;へ) </p></blockquote>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> 爬虫 </tag>
            
            <tag> lxml </tag>
            
            <tag> requests </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python爬虫-pixiv关注画师作品[1]</title>
      <link href="/blog/2019/03/27/pixiv-one/"/>
      <url>/blog/2019/03/27/pixiv-one/</url>
      
        <content type="html"><![CDATA[<img src="/blog/2019/03/27/pixiv-one/HeadPicture.jpg"><hr><blockquote><h2 id="说在前面的话"><a href="#说在前面的话" class="headerlink" title="说在前面的话"></a>说在前面的话</h2><p>本篇概述：大概有几篇是关于pixiv关注画师的作品抓取的思路和代码，后面大概还会有个个人收藏的抓取（这个比较简单）</p></blockquote><a id="more"></a><h2 id="1、pixiv介绍"><a href="#1、pixiv介绍" class="headerlink" title="1、pixiv介绍"></a>1、pixiv介绍</h2><blockquote><ul><li><a href="www.pixiv.net">Pixiv</a></li><li>这是一个墙外的网站，需要正确的扶梯姿势和科学上网</li><li>当然也可以参考我的方法（nginx + 修改 hosts 文件）</li><li>地址：<a href="https://www.lanzous.com/b649306/" target="_blank" rel="noopener">点击前往</a>  密码:3235 (建议 hosts 文件取自己需要的那部分)</li><li>为什么选 pixiv 呢？其实在12月份的时候我刚开始学 python，这个 pixiv 的小项目是我自己突发奇想要做的，那时候是新年前一周左右，对于那时候的我来说，pixiv 反爬难度一般般，但比较难的数据接口分析、构造url、文件操作、代理、图片合成等（自己一个人盯了这个网站几天，最后完成超级兴奋！）</li></ul></blockquote><h2 id="2、Target"><a href="#2、Target" class="headerlink" title="2、Target"></a>2、Target</h2><blockquote><ul><li>登录账号关注的画师的作品</li><li>思路：<ul><li>首先是模拟登录（PC 用过 pixiv 的同学都知道在未登录的时候 pixiv 会对用户做一些限制，所以我们要先模拟登录）</li><li>其次保持会话连接（可以考虑 cookie 保存，这里采用的是 requests 的 session 会话连接）</li><li>（基于图片网站，可能是动态加载，那么需要分析接口或者是 selenium 模拟）</li><li>最后才进行网页内容分析，然后抓取保存下来</li></ul></li></ul></blockquote><hr><h2 id="3、登录模拟实现流程"><a href="#3、登录模拟实现流程" class="headerlink" title="3、登录模拟实现流程"></a>3、登录模拟实现流程</h2><blockquote><h3 id="一、查找登录接口"><a href="#一、查找登录接口" class="headerlink" title="一、查找登录接口"></a>一、查找登录接口</h3></blockquote><ul><li>第一次找关于登录接口的时候，一个login都没看到，只看到一个 <a href="http://www.pixiv.net" target="_blank" rel="noopener">www.pixiv.net</a>     ,可惜是get请求的页面。</li><li>在拜读了 <a href="https://blog.csdn.net/df0128/article/details/80953212" target="_blank" rel="noopener">Chrome使用技巧</a> 、<a href="https://blog.csdn.net/Letasian/article/details/78461438" target="_blank" rel="noopener">Chrome开发者工具使用小技巧</a> 后，算是对 chrome 的调试工具有个大概了解的印象，知道了 preserve log 勾选后，可以保留网络日志，于是发现了真正的登录请求</li></ul><img src="/blog/2019/03/27/pixiv-one/1.png"><blockquote><h3 id="分析参数"><a href="#分析参数" class="headerlink" title="分析参数"></a>分析参数</h3></blockquote><p>password：个人密码</p><p>pixiv_id：个人id</p><p>post_key：不明字符串</p><p>source：pc即电脑端（截图没截全，把return_to漏掉了。。。）</p><p>return_to：是登录成功后跳转的页面，这个可以自己填，貌似默认是 <a href="https://www.pixiv.net/" target="_blank" rel="noopener">https://www.pixiv.net/</a></p><blockquote><h3 id="那么接下来就是找post-key了"><a href="#那么接下来就是找post-key了" class="headerlink" title="那么接下来就是找post_key了"></a>那么接下来就是找post_key了</h3></blockquote><ul><li>首先pixiv非常友好，所以应该不是js加密，而是在页面中随机生成的。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 其次在点击登录的时候就跳转 url1 ↓</span></span><br><span class="line"><span class="comment"># url1 = https://accounts.pixiv.net/login?lang=zh&amp;source=pc&amp;view_type=page&amp;ref=wwwtop_accounts_index</span></span><br><span class="line"><span class="comment"># 但是登录请求的 url 是 url2 ↓</span></span><br><span class="line"><span class="comment"># url2 = https://accounts.pixiv.net/api/login?lang=zh</span></span><br><span class="line"><span class="comment"># 所以猜想 post_key 应该是在前者中生成的。</span></span><br></pre></td></tr></table></figure><blockquote><p>F12 打开，在 Elements 中 Ctrl + F 查看 post_key</p></blockquote><img src="/blog/2019/03/27/pixiv-one/2.png"><blockquote><p> 接下来用 BeautifulSoup 匹配</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">self.post_key = post_key_soup.find(<span class="string">'input'</span>) [<span class="string">'value'</span>]</span><br><span class="line"><span class="comment"># 因为是第一个input标签，而find返回的是第一个符合要求的结果</span></span><br></pre></td></tr></table></figure><blockquote><p>接着向 url2 发去 post 请求</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">data = &#123;</span><br><span class="line">    <span class="string">'pixiv_id'</span>: self.pixiv_id,</span><br><span class="line">    <span class="string">'password'</span>: self.password,</span><br><span class="line">    <span class="string">'return_to'</span>: self.return_to,</span><br><span class="line">    <span class="string">'post_key'</span>: self.post_key&#125;</span><br><span class="line">rep = se.post(self.login_url, data=data, headers=self.headers,verify=<span class="keyword">False</span>)</span><br><span class="line"><span class="comment"># login_url是上面的 url2</span></span><br><span class="line"><span class="comment"># 我这里 return_to 写的是个人关注画师的那个页面的 url</span></span><br></pre></td></tr></table></figure><blockquote><h3 id="登录代码"><a href="#登录代码" class="headerlink" title="登录代码"></a>登录代码</h3></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line">se = requests.session()</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">login</span><span class="params">(self)</span>:</span></span><br><span class="line">    post_key_html = self.request(self.base_url)<span class="comment"># base_url 是上面的 url1</span></span><br><span class="line">    post_key_soup = BeautifulSoup(post_key_html.text, <span class="string">'lxml'</span>)</span><br><span class="line">    self.post_key = post_key_soup.find(<span class="string">'input'</span>)[<span class="string">'value'</span>]</span><br><span class="line">    print(self.post_key)    <span class="comment">#捕获postkey</span></span><br><span class="line">    data = &#123;</span><br><span class="line">        <span class="string">'pixiv_id'</span>: self.pixiv_id,</span><br><span class="line">        <span class="string">'password'</span>: self.password,</span><br><span class="line">        <span class="string">'return_to'</span>: self.return_to,</span><br><span class="line">        <span class="string">'post_key'</span>: self.post_key&#125;</span><br><span class="line">    rep = se.post(self.login_url, data=data, headers=self.headers,verify=<span class="keyword">False</span>)</span><br><span class="line">    <span class="comment"># login_url 是上面的 url2</span></span><br><span class="line">    print(<span class="string">'登陆成功'</span>)</span><br></pre></td></tr></table></figure><blockquote><h3 id="顺便吐槽下-HTTPS-的证书报警问题"><a href="#顺便吐槽下-HTTPS-的证书报警问题" class="headerlink" title="顺便吐槽下 HTTPS 的证书报警问题"></a>顺便吐槽下 HTTPS 的证书报警问题</h3></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> requests.packages.urllib3.exceptions <span class="keyword">import</span> InsecureRequestWarning     <span class="comment">#强制取消警告</span></span><br><span class="line">requests.packages.urllib3.disable_warnings(InsecureRequestWarning)</span><br></pre></td></tr></table></figure><h2 id="4、最后"><a href="#4、最后" class="headerlink" title="4、最后"></a>4、最后</h2><blockquote><p>先到这吧，明天继续写解析关注画师页面（页数），寻找数据接口，单图动图多图下载估计写不到了</p><p>へ(￣ ￣;へ) </p></blockquote>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> 爬虫 </tag>
            
            <tag> lxml </tag>
            
            <tag> requests </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Next主题集成 algolia 站内搜索插件</title>
      <link href="/blog/2019/03/26/algolia/"/>
      <url>/blog/2019/03/26/algolia/</url>
      
        <content type="html"><![CDATA[<img src="/blog/2019/03/26/algolia/HeadPicture.jpg"><hr><blockquote><h2 id="说在前面的话"><a href="#说在前面的话" class="headerlink" title="说在前面的话"></a>说在前面的话</h2><p>本篇概述：Next主题集成algolia </p></blockquote><a id="more"></a><h3 id="一、简述"><a href="#一、简述" class="headerlink" title="一、简述"></a>一、简述</h3><ul><li>今天添加并完善了下blog的站内搜索（既然next有集成，为何不用呢？）</li><li>主要是参考了几篇超级详细的文章</li><li>大赞：<a href="http://www.qingpingshan.com/m/view.php?aid=386198" target="_blank" rel="noopener">Hexo+Next集成Algolia搜索</a>、<a href="https://www.zhihu.com/question/46822587" target="_blank" rel="noopener">知乎</a></li></ul><h3 id="二、问题枪毙名单"><a href="#二、问题枪毙名单" class="headerlink" title="二、问题枪毙名单"></a>二、问题枪毙名单</h3><h4 id="1-Not-enough-rights-to-update-an-object-near"><a href="#1-Not-enough-rights-to-update-an-object-near" class="headerlink" title="1. Not enough rights to update an object near"></a>1. Not enough rights to update an object near</h4><ul><li>解决方法：修改Algolia的ACL访问控制列表</li><li><img src="/blog/2019/03/26/algolia/1.png"></li><li><img src="/blog/2019/03/26/algolia/2.png"></li><li>将ACL修改为以上所示，文章里的ACL和现在的界面不一样，不知道是我用得少的原因(雾)，找了几分钟左右。</li></ul><h4 id="2-Please-provide-an-Algolia-index-name-in-your-hexo-config-yml-flle"><a href="#2-Please-provide-an-Algolia-index-name-in-your-hexo-config-yml-flle" class="headerlink" title="2. Please provide an Algolia index name in your hexo _config.yml flle"></a>2. Please provide an Algolia index name in your hexo _config.yml flle</h4><ul><li>解决方法：修改index名称</li><li>index名称就是在以下这个界面输入的那个index name</li><li><img src="/blog/2019/03/26/algolia/3.png"></li></ul><h4 id="3-ERROR-Algolia-Please-set-an-HEXO-ALGOLIA-INDEXING-KEY-environment-variable-to-enable-content-indexing"><a href="#3-ERROR-Algolia-Please-set-an-HEXO-ALGOLIA-INDEXING-KEY-environment-variable-to-enable-content-indexing" class="headerlink" title="3. ERROR [Algolia] Please set an HEXO_ALGOLIA_INDEXING_KEY environment variable to enable content indexing."></a>3. ERROR [Algolia] Please set an <code>HEXO_ALGOLIA_INDEXING_KEY</code> environment variable to enable content indexing.</h4><ul><li><p>这个通常是在hexo algolia的时候出现的问题</p></li><li><p>其实在上面的文章也有说到，这里简单说一下</p></li><li><p>解决方法：</p></li><li><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="builtin-name">export</span> HEXO_ALGOLIA_INDEXING_KEY=[你的API Key]</span><br></pre></td></tr></table></figure></li><li><p>API Key 是 Search-Only API key</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> hexo </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hexo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>lxml&amp;Xpath</title>
      <link href="/blog/2019/03/13/xpath/"/>
      <url>/blog/2019/03/13/xpath/</url>
      
        <content type="html"><![CDATA[<img src="/blog/2019/03/13/xpath/HeadPicture.png"><hr><blockquote><h2 id="说在前面的话"><a href="#说在前面的话" class="headerlink" title="说在前面的话"></a>说在前面的话</h2><p>本篇概述：Xpath语法，lxml解析html</p></blockquote><a id="more"></a><h3 id="一、什么是Xpath"><a href="#一、什么是Xpath" class="headerlink" title="一、什么是Xpath?"></a>一、什么是Xpath?</h3><ol><li>XPath 是 XML 路径语言，主要是在 XML 和 HTML 文档中查找我们想要的信息的语言。</li><li>XML 和 HTML 一样也是标记语言，但是 XML 用来传输和存储数据，而 HTML 用来显示数据</li></ol><h3 id="二、Xpath工具"><a href="#二、Xpath工具" class="headerlink" title="二、Xpath工具"></a>二、Xpath工具</h3><ol><li>Google：Xpath Helper</li></ol><p>（Google 插件可到下载<a href="https://www.crx4chrome.com/" target="_blank" rel="noopener">Crx4Chrom</a>(英文)、<a href="http://www.cnplugins.com/" target="_blank" rel="noopener">插件网</a>、<a href="http://chromecj.com/" target="_blank" rel="noopener">Chrome插件网 </a>下载）</p><ol><li>Firefox：Try Xpath</li><li>每个浏览器一般在应用中心或拓展里都可以下载</li></ol><blockquote><p>Xpath Helper 界面</p></blockquote><img src="/blog/2019/03/13/xpath/1.png"><h3 id="三、Xpath语法"><a href="#三、Xpath语法" class="headerlink" title="三、Xpath语法"></a>三、Xpath语法</h3><h4 id="1、路径表达式语法、相对-绝对路径"><a href="#1、路径表达式语法、相对-绝对路径" class="headerlink" title="1、路径表达式语法、相对/绝对路径"></a>1、路径表达式语法、相对/绝对路径</h4><table><thead><tr><th style="text-align:center">表达式</th><th style="text-align:center">路径表达式及描述</th></tr></thead><tbody><tr><td style="text-align:center">节点名称</td><td style="text-align:center">bookstore，选取 bookstore 下的所有子节点(标签)</td></tr><tr><td style="text-align:center">/</td><td style="text-align:center">/bookstore，从根节点下选取所有 bookstore 节点(子元素)</td></tr><tr><td style="text-align:center">//</td><td style="text-align:center">//bookstore，从全局节点中选择 bookstore 节点</td></tr><tr><td style="text-align:center">@</td><td style="text-align:center">//div[@price=‘a’]，选择所有 price 属性为 a 的 div</td></tr><tr><td style="text-align:center">.</td><td style="text-align:center">./input，选择当前节点下的 input</td></tr></tbody></table><h4 id="2、谓语"><a href="#2、谓语" class="headerlink" title="2、谓语"></a>2、谓语</h4><p>html 节点中第一个节点为 1，第二个为 2（需要区分）</p><table><thead><tr><th style="text-align:center">表达式</th><th style="text-align:center">描述</th></tr></thead><tbody><tr><td style="text-align:center">//ul/li[1]</td><td style="text-align:center">选择 ul 下的第一个 li</td></tr><tr><td style="text-align:center">//ul/li[last()-0]</td><td style="text-align:center">选择 ul 下的最后一个 li</td></tr><tr><td style="text-align:center">//ul/li[last()-1]</td><td style="text-align:center">选择 ul 下的倒数第二个 li</td></tr><tr><td style="text-align:center">//ul/li[position()&lt;4]</td><td style="text-align:center">选择 ul 下前面的 3 个子元素</td></tr><tr><td style="text-align:center">//ul/li[position()&gt;1]</td><td style="text-align:center">选择第二个到最后的所有子元素</td></tr><tr><td style="text-align:center">//li[position()&gt;1] [position()&lt;11]</td><td style="text-align:center">在(2,+∞)中选择前十个</td></tr><tr><td style="text-align:center">text()</td><td style="text-align:center">获取函数文本</td></tr><tr><td style="text-align:center">@class</td><td style="text-align:center">获取标签的class</td></tr></tbody></table><img src="/blog/2019/03/13/xpath/2.png"><h4 id="通配符"><a href="#通配符" class="headerlink" title="通配符"></a>通配符</h4><table><thead><tr><th style="text-align:center">*</th><th style="text-align:center">/bookstore/*，通配符，匹配 bookstore 下的所有子元素</th></tr></thead><tbody><tr><td style="text-align:center">@*</td><td style="text-align:center">//div[@*]，选择所有带有属性的 div</td></tr></tbody></table><h4 id="运算符"><a href="#运算符" class="headerlink" title="运算符"></a>运算符</h4><ul><li>“|“    —&gt;    //title | //ul[@class=‘item_con_list’]，选择 title 和对应的 ul</li></ul><h3 id="四、使用lxml-amp-xpath解析html"><a href="#四、使用lxml-amp-xpath解析html" class="headerlink" title="四、使用lxml&amp;xpath解析html"></a>四、使用lxml&amp;xpath解析html</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">html1 = etree.parse(index.html)<span class="comment"># 可以通过读取html文件的方式</span></span><br><span class="line">html2 = etree.HTML(text)<span class="comment"># 也可以将字符串解析为HTML文档</span></span><br><span class="line"></span><br><span class="line">result1 = etree.tostring(html2)<span class="comment"># 将字符串序列化成HTML文档,会自动补全</span></span><br><span class="line"></span><br><span class="line">result2 = html2.xpath(<span class="string">'表达式'</span>)  <span class="comment"># 使用xpath语法</span></span><br></pre></td></tr></table></figure><h3 id="五、Example"><a href="#五、Example" class="headerlink" title="五、Example"></a>五、Example</h3><ul><li>以<a href="https://hr.tencent.com/position.php?lid=2218&amp;start=0#a" target="_blank" rel="noopener">腾讯招聘网</a>为例</li><li>我们要获取到职位名称、职位类别、人数、地点和发布时间等内容</li></ul><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="regexp">//</span>table<span class="regexp">//</span>tr</span><br></pre></td></tr></table></figure><p>选择到了13个子元素，分别是表头，翻页和底部其他招聘</p><img src="/blog/2019/03/13/xpath/3.png"><img src="/blog/2019/03/13/xpath/4.png">    <ul><li>那么可以往上找父元素，扩大范围</li></ul><img src="/blog/2019/03/13/xpath/5.png">    <figure class="highlight perl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">//table[@class=<span class="string">'tablelist'</span>]//<span class="keyword">tr</span>[@class=<span class="string">'even'</span>] | <span class="regexp">//table</span>[@class=<span class="string">'tablelist'</span>]//<span class="keyword">tr</span>[@class=<span class="string">'odd'</span>]</span><br></pre></td></tr></table></figure><ul><li>使用以上表达式，避开表头和翻页</li><li>上述表达式虽然精确但是有点冗长，鉴于网站规律性，可以采用以下表达式</li></ul><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">//table[<span class="string">@class='tablelist'</span>]//tr[<span class="string">position()&gt;1</span>][<span class="symbol">position()&lt;11</span>]</span><br></pre></td></tr></table></figure><ul><li>上面的表达式写在程序里不加text()来取的话，会返回类似 <element tr="" at="" 0x1df36b5bc08=""> 的结果。</element></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">headers = &#123;</span><br><span class="line"><span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3626.109 Safari/537.36'</span></span><br><span class="line">&#125;</span><br><span class="line">url = <span class="string">'https://hr.tencent.com/position.php?lid=2218&amp;start=0#a'</span></span><br><span class="line">html = requests.get(url=url,headers=headers)<span class="comment"># html.text未经过编码的字符串，unicode字符串</span></span><br><span class="line">etree_obj = etree.HTML(html.text)<span class="comment"># HTML解析的是字符串，所以html.text</span></span><br><span class="line">result1 = etree_obj.xpath(<span class="string">"//table[@class='tablelist']//tr[position()&gt;1][position()&lt;11]//text()"</span>)</span><br><span class="line">result2 = etree_obj.xpath(<span class="string">"//table[@class='tablelist']//tr[position()&gt;1][position()&lt;11]"</span>)</span><br><span class="line">print(result1)</span><br><span class="line">print(result2)</span><br></pre></td></tr></table></figure><img src="/blog/2019/03/13/xpath/6.png"><ul><li><p>结果可以看到有许多的转义字符，比如：\r、\t</p></li><li><p>最后将代码处理一下，照此方法可以获取到腾讯招聘的所有职位信息(后面有个坑，比如职位类别是空数据的话，XPath匹配到会自动放弃)</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">headers = &#123;</span><br><span class="line"><span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3626.109 Safari/537.36'</span></span><br><span class="line">&#125;</span><br><span class="line">url = <span class="string">'https://hr.tencent.com/position.php?lid=2218&amp;start=0#a'</span></span><br><span class="line">html = requests.get(url=url,headers=headers)<span class="comment"># html.text未经过编码的字符串，unicode字符串</span></span><br><span class="line">etree_obj = etree.HTML(html.text)<span class="comment"># HTML解析的是字符串，所以html.text</span></span><br><span class="line">result = etree_obj.xpath(<span class="string">"//table[@class='tablelist']//tr[position()&gt;1][position()&lt;11]//text()"</span>)</span><br><span class="line">print(result)</span><br><span class="line">result2 = [x.strip() <span class="keyword">for</span> x <span class="keyword">in</span> result <span class="keyword">if</span> x.strip() != <span class="string">''</span>]</span><br><span class="line">print(result2)</span><br><span class="line">result3 = [print(result2[x],result2[x+<span class="number">1</span>],result2[x+<span class="number">2</span>],result2[x+<span class="number">3</span>],result2[x+<span class="number">4</span>]) <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">0</span>,len(result2),<span class="number">5</span>)]</span><br><span class="line">print(result3)</span><br></pre></td></tr></table></figure><ul><li>结果图</li></ul><img src="/blog/2019/03/13/xpath/7.png"><ul><li><h4 id="本篇代码Github地址：https-github-com-Coder-Sakura-exp-tree-master-xpath"><a href="#本篇代码Github地址：https-github-com-Coder-Sakura-exp-tree-master-xpath" class="headerlink" title="本篇代码Github地址：https://github.com/Coder-Sakura/exp/tree/master/xpath"></a>本篇代码Github地址：<a href="https://github.com/Coder-Sakura/exp/tree/master/xpath" target="_blank" rel="noopener">https://github.com/Coder-Sakura/exp/tree/master/xpath</a></h4></li></ul>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> 爬虫 </tag>
            
            <tag> Xpath </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>关于git的操作的一些记录</title>
      <link href="/blog/2019/03/03/git-note/"/>
      <url>/blog/2019/03/03/git-note/</url>
      
        <content type="html"><![CDATA[<img src="/blog/2019/03/03/git-note/HeadPicture.png"><hr><blockquote><h2 id="说在前面的话"><a href="#说在前面的话" class="headerlink" title="说在前面的话"></a>说在前面的话</h2><p>本篇概述：主要记录git的命令和一些git的知识</p></blockquote><a id="more"></a><h3 id="一、github介绍"><a href="#一、github介绍" class="headerlink" title="一、github介绍"></a>一、github介绍</h3><p><a href="https://github.com/" target="_blank" rel="noopener">github</a>(<del>基佬站</del>)是一个开源代码托管平台(其中当然也有私有项目)，也作为一个版本控制系统，让你对代码的版本控制更加简单，不用去担心代码写错了怎么办？有没有备份？专心自己的项目就好。</p><p>本文没有关于桌面版的git安装、环境变量配置的教程(安装配置的话百度有很多教程)</p><img src="/blog/2019/03/03/git-note/1.jpg"><h3 id="二、github功能"><a href="#二、github功能" class="headerlink" title="二、github功能"></a>二、github功能</h3><ol><li>可以在上面找到许多开源项目、脚本甚至可以在上面找到一些课程</li><li>托管项目。只要连上互联网就可以同步到自己的项目代码或多人跟进项目</li><li>利用github和一些开源的博客系统可以搭建个人博客(本博客是hexo+github搭建的)</li></ol><h3 id="三、git命令"><a href="#三、git命令" class="headerlink" title="三、git命令"></a>三、git命令</h3><ol><li><font color="#FF3030">设置用户名和邮箱</font>，不设置会报“please tell me who you are.”，–global参数表示全局</li></ol><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git<span class="built_in"> config </span>--global user.name <span class="string">"Your Name"</span></span><br><span class="line">git<span class="built_in"> config </span>--global user.email <span class="string">"email@example.com"</span></span><br><span class="line">git<span class="built_in"> config </span>--list # 检查设置</span><br></pre></td></tr></table></figure><ol start="2"><li>初始化本地文件夹为git仓库（会生成.git隐藏文件，主要是用于版本控制）</li></ol><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">git init</span></span><br></pre></td></tr></table></figure><ol start="3"><li>本地版本管理</li></ol><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">git add ./[name]<span class="comment"># 跟踪文件进入暂存区，.表示当前目录所有文件，也可以指定文件</span></span><br><span class="line">git status<span class="comment"># 命令用于显示工作目录和暂存区的状态</span></span><br><span class="line">git <span class="keyword">commit</span> -m <span class="string">'提交说明'</span> <span class="comment"># 将暂存区里的改动给提交到本地的版本库</span></span><br><span class="line">git <span class="keyword">log</span> <span class="comment">--pretty=oneline# 查看最近到最远的提交日志，oneline表示每条输出一行</span></span><br><span class="line"><span class="comment">#  $ git log --pretty=oneline</span></span><br><span class="line"><span class="comment">#  f3e98b7f4495c78bf98f2661fad2ae745cd60b63 (HEAD -&gt; master, origin/master) proxy</span></span><br><span class="line"><span class="comment">#  f3e9....这串就是这次提交的版本号</span></span><br><span class="line">git <span class="keyword">reset</span> <span class="comment">--hard [版本号] # 回退/前进到某个指定版本，版本号可以在git log中找到</span></span><br><span class="line"><span class="comment">#  也有快捷的回退命令</span></span><br><span class="line">git <span class="keyword">reset</span> <span class="comment">--hard HEAD^# 回退到上个版本</span></span><br><span class="line">git <span class="keyword">reset</span> <span class="comment">--hard HEAD^^# 回退到上上个版本</span></span><br><span class="line">git <span class="keyword">reset</span> <span class="comment">--hard HEAD~100# 回退到上100个版本</span></span><br></pre></td></tr></table></figure><ol start="3"><li>将本地文件提交到github</li></ol><figure class="highlight vala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">git init</span><br><span class="line">git add ./(name)</span><br><span class="line">git commit -m <span class="string">'message'</span></span><br><span class="line">git remote add origin [github仓库地址]</span><br><span class="line"><span class="meta"># 如果出现错误：fatal: remote origin already exists</span></span><br><span class="line"><span class="meta"># 执行 git remote rm origin#删除分支</span></span><br><span class="line"><span class="meta"># 再执行 git remote add origin [github仓库地址]#再添加</span></span><br><span class="line">git push origin master# 推送到github仓库</span><br><span class="line"><span class="meta"># 如果出现failed to push som refs to…….</span></span><br><span class="line"><span class="meta"># 需要将github仓库的文件同步下来先</span></span><br><span class="line"><span class="meta"># git pull origin master# pull拉文件下来</span></span><br><span class="line"><span class="meta"># 再执行 git push origin master# push推文件上去</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> git </category>
          
      </categories>
      
      
        <tags>
            
            <tag> git </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python爬虫[代理]</title>
      <link href="/blog/2019/02/28/proxy/"/>
      <url>/blog/2019/02/28/proxy/</url>
      
        <content type="html"><![CDATA[<img src="/blog/2019/02/28/proxy/HeadPicture.png"><hr><blockquote><h2 id="说在前面的话"><a href="#说在前面的话" class="headerlink" title="说在前面的话"></a>说在前面的话</h2><p>本篇概述：代理原理作用，requests设置代理方法以及爬取免费代理的脚本实例</p></blockquote><a id="more"></a><h3 id="一、代理原理"><a href="#一、代理原理" class="headerlink" title="一、代理原理"></a>一、代理原理</h3><img src="/blog/2019/02/28/proxy/proxy_1.png"><p>根据自己理解解读：</p><ol><li>客户端设置了代理信息后，客户端向对应的代理站点发出请求（向xxx网站发起请求）</li><li>代理站点收到请求之后，就会执行对应的响应动作（执行动作）</li><li>代理站点获得xxx网站的响应（得到站点响应）</li><li>代理站点根据客户端要求返回对应信息（客户端要求返回Source code，则返回Source code）</li></ol><h3 id="二、代理作用"><a href="#二、代理作用" class="headerlink" title="二、代理作用"></a>二、代理作用</h3><ol><li>突破自身ip访问限制，比如访问国外站点</li><li>爬取对ip访问频率有一定限制的站点</li><li>提高访问速度</li><li>隐藏真实ip</li></ol><h3 id="三、代理网站"><a href="#三、代理网站" class="headerlink" title="三、代理网站"></a>三、代理网站</h3><p><strong>免费代理ip列表</strong>：</p><table><thead><tr><th>含国外ip</th><th><a href="https://ip.seofangfa.com/" target="_blank" rel="noopener">方法SEO顾问</a>，<a href="http://www.89ip.cn/" target="_blank" rel="noopener">89代理</a>，<a href="https://ip.ihuan.me/" target="_blank" rel="noopener">小幻http代理</a>，<a href="http://www.ip3366.net/" target="_blank" rel="noopener">云代理</a></th></tr></thead><tbody><tr><td>不含</td><td><a href="https://www.xicidaili.com/" target="_blank" rel="noopener">西刺</a>，<a href="https://www.kuaidaili.com/" target="_blank" rel="noopener">快代理</a></td></tr></tbody></table><p><strong>付费代理尚未了解，此处留空</strong></p><h3 id="四、requests设置代理方法"><a href="#四、requests设置代理方法" class="headerlink" title="四、requests设置代理方法"></a>四、requests设置代理方法</h3><p>requests中有预设好的参数接收代理信息 proxies，这个参数接收的是一个字典对象</p><p>因为不知道访问的网站使用的是http协议还是https协议，所以proxies最好2种都有设置</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">proxies = &#123;</span><br><span class="line">    <span class="string">'http'</span>:<span class="number">92.255</span><span class="number">.255</span><span class="number">.78</span>:<span class="number">54628</span>,</span><br><span class="line">    <span class="string">'https'</span>:<span class="number">92.255</span><span class="number">.255</span><span class="number">.78</span>:<span class="number">54628</span></span><br><span class="line">&#125;</span><br><span class="line">resp = requests.get(url=url1,headers=headers,proxies=proxies)</span><br></pre></td></tr></table></figure><h3 id="五、脚本示例"><a href="#五、脚本示例" class="headerlink" title="五、脚本示例"></a>五、脚本示例</h3><p>github地址：<a href="https://github.com/Coder-Sakura/exp/tree/master/seo_ip" target="_blank" rel="noopener">https://github.com/Coder-Sakura/exp/tree/master/seo_ip</a></p><p>本来我是打算用89代理的api接口，但是测试之后发现可靠性有点低，并且外网ip比较少，所以转用<a href="https://ip.seofangfa.com/" target="_blank" rel="noopener">SEO</a></p><p>（本次抓取代理ip主要是用在我自己做 <a href="http://www.pixiv.net" target="_blank" rel="noopener">pixiv</a> 的小项目上，爬取关注画师的所有作品和自己的收藏作品，后续会整理出来，初学爬虫，有错还请指正）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">from</span> requests.packages.urllib3.exceptions <span class="keyword">import</span> InsecureRequestWarning     <span class="comment"># 用于强制取消警告</span></span><br><span class="line"><span class="keyword">from</span> requests.adapters <span class="keyword">import</span> HTTPAdapter                                   <span class="comment"># 用于强制取消警告</span></span><br><span class="line"></span><br><span class="line">requests.packages.urllib3.disable_warnings(InsecureRequestWarning)      <span class="comment"># 强制取消警告</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">seo_ip</span><span class="params">()</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.headers = &#123;</span><br><span class="line">            <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 10.0; WOW64) '</span></span><br><span class="line">                          <span class="string">'AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36'</span>&#125;</span><br><span class="line">        self.agent_ip_list = []</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">Agent</span><span class="params">(self,ip_agent_url)</span>:</span></span><br><span class="line">        html = requests.get(url=ip_agent_url,headers=self.headers,verify=<span class="keyword">False</span>,timeout=<span class="number">5</span>)</span><br><span class="line">        html_soup = BeautifulSoup(html.text, <span class="string">'lxml'</span>)</span><br><span class="line">        <span class="comment"># 去除第一个和前25个，26-50为国外ip</span></span><br><span class="line">        ip_list = html_soup.find(<span class="string">'tbody'</span>).find_all(<span class="string">'tr'</span>)[<span class="number">26</span>:]    </span><br><span class="line">        items = []</span><br><span class="line">        print(<span class="string">'搜索完成,代理信息如下:'</span>) </span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> ip_list:        </span><br><span class="line">            ip_port = list(item)[<span class="number">0</span>].get_text() + <span class="string">':'</span> +list(item)[<span class="number">1</span>].get_text()</span><br><span class="line">            <span class="comment"># list(ip_port)[0]为ip,[1]为端口,[2]响应时间,[3]位置,[4]最后验证时间</span></span><br><span class="line">            print(<span class="string">'ip: %s ,响应时间: %ss ,ip位置: %s'</span> % (ip_port,list(item)[<span class="number">2</span>].get_text(),list(item)[<span class="number">3</span>].get_text()))</span><br><span class="line">            items.append(ip_port)        <span class="comment">#存储爬取到的ip(需要添加)</span></span><br><span class="line">        <span class="keyword">return</span> items</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">judge</span><span class="params">(self,items)</span>:</span>       <span class="comment"># 检验ip活性     # https://ip.seofangfa.com/</span></span><br><span class="line">        print(<span class="string">'正在进行代理池ip活性检测......'</span>)</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> items:</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                proxy = &#123;</span><br><span class="line">                    <span class="string">'http'</span>:item,</span><br><span class="line">                    <span class="string">'https'</span>:item</span><br><span class="line">                    &#125;</span><br><span class="line">                <span class="comment"># 遍历时，利用百度，设定timeout，未响应则断开连接</span></span><br><span class="line">                judge_url = <span class="string">'https://www.baidu.com/'</span>     </span><br><span class="line">                response = requests.get(url=judge_url,headers=self.headers,proxies=proxy,verify=<span class="keyword">False</span>,timeout=<span class="number">5</span>)</span><br><span class="line">                self.agent_ip_list.append(item)</span><br><span class="line">                print(item,<span class="string">'可用...'</span>)</span><br><span class="line">            <span class="keyword">except</span>:</span><br><span class="line">                print(item,<span class="string">'不可用...'</span>)</span><br><span class="line">        print(<span class="string">'代理池ip活性检测完毕...\n代理池总量:'</span>,len(self.agent_ip_list),<span class="string">'\n代理池:'</span>,self.agent_ip_list)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">work</span><span class="params">(self)</span>:</span></span><br><span class="line">        ip_agent_url = <span class="string">'https://ip.seofangfa.com/'</span></span><br><span class="line">        items = self.Agent(ip_agent_url)</span><br><span class="line">        self.judge(items)</span><br><span class="line"></span><br><span class="line">seo_ip = seo_ip()</span><br><span class="line">seo_ip.work()</span><br></pre></td></tr></table></figure><p>没有导入这2个库的话，会因为ssl证书而出现警告，如图：</p><ol><li>from requests.packages.urllib3.exceptions import InsecureRequestWarning</li><li>from requests.adapters import HTTPAdapter</li></ol><img src="/blog/2019/02/28/proxy/proxy_2.png"><h3 id="六、附图"><a href="#六、附图" class="headerlink" title="六、附图"></a>六、附图</h3><blockquote><p> 最后附上运行图</p></blockquote><img src="/blog/2019/02/28/proxy/proxy_3.png">]]></content>
      
      
      <categories>
          
          <category> proxy </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> 爬虫 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python第三方库安装[pip、whl]</title>
      <link href="/blog/2019/02/12/212/"/>
      <url>/blog/2019/02/12/212/</url>
      
        <content type="html"><![CDATA[<img src="/blog/2019/02/12/212/HeadPicture.jpg"><hr><blockquote><h2 id="说在前面的话"><a href="#说在前面的话" class="headerlink" title="说在前面的话"></a>说在前面的话</h2><p>本篇概述：python第三方库安装</p></blockquote><a id="more"></a><h3 id="一、pip安装"><a href="#一、pip安装" class="headerlink" title="一、pip安装"></a>一、pip安装</h3><ul><li>pip3 install [库名] 或 pip install [库名]</li></ul><hr><blockquote><h4 id="2019-02-28更新"><a href="#2019-02-28更新" class="headerlink" title="[2019.02.28更新]"></a>[2019.02.28更新]</h4></blockquote><p>针对 ‘pip’ 不是内部命令，也不是可运行的程序的情况：</p><p>原因：环境变量 Path 未配置完成</p><ol><li>找到 python 的安装目录，将 <font color="#FF3030">python 的安装目录</font> 和 <font color="#FF3030">Python安装目录\Scripts</font> 添加到 环境变量 Path 中即可；</li><li>环境变量Path：计算机属性 -&gt; 高级系统设置 -&gt; 高级 -&gt; 环境变量</li></ol><img src="/blog/2019/02/12/212/3.png"><h3 id="二、whl安装"><a href="#二、whl安装" class="headerlink" title="二、whl安装"></a>二、whl安装</h3><div><div class="fold_hider"><div class="close hider_title"><u>点我可以将内容伸缩哦~</u></div></div><div class="fold"><p>٩(๑&gt;◡&lt;๑)۶</p><blockquote><ul><li>如果pip安装不行，可以考虑whl安装(轮子大法好！) </li><li><a href="https://www.lfd.uci.edu/~gohlke/pythonlibs/" target="_blank" rel="noopener">Python常用库whl文件下载</a></li><li>如何知道本机安装的python支持哪个版本的轮子?</li></ul></blockquote><h5 id="首先要知道系统是多少位的？-在cmd中输入"><a href="#首先要知道系统是多少位的？-在cmd中输入" class="headerlink" title="首先要知道系统是多少位的？(在cmd中输入)"></a>首先要知道系统是多少位的？(在cmd中输入)</h5><figure class="highlight 1c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systeminfo <span class="string">| findstr "</span>系统类型<span class="string">"</span></span><br></pre></td></tr></table></figure><p>结果：x64-based PC  = (64位 AMD64)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pip._internal</span><br><span class="line">print(pip._internal.pep425tags.get_supported())</span><br></pre></td></tr></table></figure><p>X86-based PC  = (32位 WIN32)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pip</span><br><span class="line">print(pip.pep425tags.get_supported())</span><br></pre></td></tr></table></figure><h5 id="选择对应的轮子"><a href="#选择对应的轮子" class="headerlink" title="选择对应的轮子"></a>选择对应的轮子</h5><ol><li><p>输入上面的代码后，会返回一个list，list里面就是当前系统支持的whl版本</p></li><li><p>比如 ‘cp37’, ‘cp37m’, ‘win_amd64’，cp37对应的是python3.7版本; cp37m 对应的是依赖于python3.7应用程序二进制接口; win_amd64对应的是64位系统编译的。</p></li></ol><p><img src="/blog/2019/02/12/212/1.png"></p><ol start="3"><li>打开上面的网址，ctrl + F ，这里使用 mysqlclient 作为示范</li></ol><p><img src="/blog/2019/02/12/212/2.png"></p><ol start="4"><li><p>根据刚刚的结果，下载以下版本的轮子即可。</p><p><strong>mysqlclient‑1.4.2‑cp37‑cp37m‑win_amd64.whl</strong></p></li></ol><p>​    库名 - 版本号 - 对应python版本 - 依赖 - 系统位数</p><h5 id="安装轮子"><a href="#安装轮子" class="headerlink" title="安装轮子"></a>安装轮子</h5><ol start="5"><li>进入到轮子目录，cmd打开，pip install [名字].whl 即可</li></ol><hr><blockquote><h4 id="2019-02-28更新"><a href="#2019-02-28更新" class="headerlink" title="[2019.02.28更新]"></a>[2019.02.28更新]</h4></blockquote><p>针对 pip install [名字].whl 安装不成功的情况</p><ol><li>可以将whl文件的后缀名.whl更改为.zip，然后解压</li><li>在解压目录下进行 python setup.py install 运行安装[通常whl文件解压后都有setup.py]</li><li>对于没有 setup.py 的，直接将解压目录放入libs文件夹中</li><li>whl文件是已经编译好的文件，作用主要是为了方便我们进行 python 的第三方库安装和使用</li></ol></div></div><h3 id="三、Anaconda"><a href="#三、Anaconda" class="headerlink" title="三、Anaconda"></a>三、Anaconda</h3><p>​    Anaconda包括Conda、Python以及一大堆安装好的科学包和依赖项。(Conda是一个开源的包和环境的管理器)</p><p>​    从 <a href="https://www.anaconda.com/distribution/" target="_blank" rel="noopener">Anaconda官网</a> 下载，图形化安装，十分简单，而且网上的教程也多。</p>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> 第三方库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/blog/2019/02/09/hello-world/"/>
      <url>/blog/2019/02/09/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.    </p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
